{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:38.356525Z",
     "start_time": "2018-06-16T19:24:38.328112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.112635Z",
     "start_time": "2018-06-16T19:24:38.359592Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from io import StringIO\n",
    "from textwrap import dedent\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.single_sided_network_v2 import network_slh\n",
    "\n",
    "from doit.tools import register_doit_as_IPython_magic\n",
    "import clusterjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.153330Z",
     "start_time": "2018-06-16T19:24:42.116055Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOIT_CONFIG = {\n",
    "    'backend': 'json',\n",
    "    'dep_file': '.doit_db/2018-06-12_mg_oct_single_excitation_three_pulses.json',\n",
    "}\n",
    "register_doit_as_IPython_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.192897Z",
     "start_time": "2018-06-16T19:24:42.155990Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterjob.JobScript.read_defaults('./config/mlhpc_cluster.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.364764Z",
     "start_time": "2018-06-16T19:24:42.195074Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDYN 2.0dev revision dfd21683b898e790985b519daac35aeef7721f6c (master)\r\n",
      "  features: no-check-cheby, no-check-newton, no-parallel-ham, use-mkl=sequential, use-mpi=intel, parallel-oct, backtraces, no-debug, no-no-ipo\r\n",
      "  compiled with ifort on Mon Nov 13 14:54:23 2017 on host mlhpc2\r\n"
     ]
    }
   ],
   "source": [
    "! qdyn_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{ket}[1]{\\vert #1 \\rangle}\n",
    "\\newcommand{bra}[1]{\\langle #1 \\vert}\n",
    "\\newcommand{Op}[1]{\\hat{#1}}\n",
    "$\n",
    "\n",
    "# Compare variants of Krotov's method for optimization of a large-N Dicke state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.409328Z",
     "start_time": "2018-06-16T19:24:42.369521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = './data/oct_single_excitation_three_pulses/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.468100Z",
     "start_time": "2018-06-16T19:24:42.411901Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runfolder(row):\n",
    "    int_part, frac_part = (\"%.2f\" % row['T']).split('.')\n",
    "    nt = row['nt']\n",
    "    if frac_part == '00':\n",
    "        if int(nt) == 500:\n",
    "            T_str = \"%s\" % int_part\n",
    "        else:\n",
    "            T_str = \"%s_nt%s\" % (int_part, nt)\n",
    "    else:\n",
    "        if int(nt) == 500:\n",
    "            T_str = '%s_%s' % (int_part, frac_part)\n",
    "        else:\n",
    "            T_str = '%s_%s_nt%s' % (int_part, frac_part, nt)\n",
    "    rf = \"%02dnodesT%s_%s_ntrajs%s\" % (\n",
    "        row['nodes'], T_str, row['variant'], row['n_trajs'])\n",
    "    return join(ROOT, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLH Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For very large networks, the SLH models take a significant amount of time to calculate, so we'll want to cache them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.503758Z",
     "start_time": "2018-06-16T19:24:42.470570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SLH_MODELS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.656432Z",
     "start_time": "2018-06-16T19:24:42.506566Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p {ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.699742Z",
     "start_time": "2018-06-16T19:24:42.660869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SLH_PICKLE_FILE = join(ROOT, \"slh_models.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.755838Z",
     "start_time": "2018-06-16T19:24:42.702839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(SLH_PICKLE_FILE):\n",
    "    with open(SLH_PICKLE_FILE, 'rb') as pickle_fh:\n",
    "        SLH_MODELS.update(pickle.load(pickle_fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:42.796287Z",
     "start_time": "2018-06-16T19:24:42.759003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLH_MODELS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.111603Z",
     "start_time": "2018-06-16T19:24:42.798628Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.doit_actions_v2 import (\n",
    "    update_config, wait_for_clusterjob, run_traj_prop,\n",
    "    write_rho_prop_custom_config, collect_rho_prop_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.184172Z",
     "start_time": "2018-06-16T19:24:43.114431Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit_optimization(rf, n_trajs, variant, task):\n",
    "    \"\"\"Asynchronously run optimization, using either the\n",
    "    standard QDYN implementation (variant = 'normal') or the 'crossoct' QDYN\n",
    "    implementation at a particular revision (variant='cross')\n",
    "\n",
    "    Does not support use of MPI, so this should only run on a workstation with\n",
    "    more cores than the total number of trajectories\n",
    "    \"\"\"\n",
    "    if os.path.isfile(join(rf, 'oct.job.dump')):\n",
    "        return\n",
    "    bodies = {\n",
    "        'normal': dedent(r'''\n",
    "            {module_load}\n",
    "            cd $CLUSTERJOB_WORKDIR\n",
    "            pwd\n",
    "            OMP_NUM_THREADS={threads} \\\n",
    "              qdyn_optimize --n-trajs={n_trajs} --J_T=J_T_ss .'''),\n",
    "        'cross': dedent(r'''\n",
    "            {module_load}\n",
    "            module load prefix/crossoct\n",
    "\n",
    "            qdyn_version | grep 66f6d24d2b07b9cc || {cancel_cmd}\n",
    "\n",
    "            cd $CLUSTERJOB_WORKDIR\n",
    "            pwd\n",
    "            OMP_NUM_THREADS={threads} \\\n",
    "              qdyn_optimize --n-trajs={n_trajs} --J_T=J_T_cross .''')}\n",
    "    body = bodies[variant]\n",
    "    taskname = \"oct_%s\" % task.name.split(\":\")[-1]\n",
    "    jobscript = clusterjob.JobScript(\n",
    "        body=body, jobname=taskname, workdir=rf,\n",
    "        stdout='oct.log')\n",
    "    jobscript.n_trajs = str(int(n_trajs))\n",
    "    jobscript.resources['ppn'] = 1 # not using MPI\n",
    "    jobscript.resources['threads'] = min(int(n_trajs), 78)\n",
    "    jobscript.threads = str(jobscript.resources['threads'])\n",
    "    run = jobscript.submit(cache_id=taskname)\n",
    "    run.dump(join(rf, 'oct.job.dump'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom uptodate routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.234859Z",
     "start_time": "2018-06-16T19:24:43.186948Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.qdyn_model_v2 import pulses_uptodate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCT task definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.279076Z",
     "start_time": "2018-06-16T19:24:43.237391Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.qdyn_single_excitation_model_v1 import make_single_excitation_qdyn_oct_model\n",
    "from src.dicke_half_model_v2 import dicke_guess_controls, num_vals\n",
    "from sympy import Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.441255Z",
     "start_time": "2018-06-16T19:24:43.281636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_dicke_single_model_three_pulses(\n",
    "        slh, rf, T, theta=0, E0_cycles=2, mcwf=False, non_herm=False,\n",
    "        lambda_a=1.0, J_T_conv=1e-4, iter_stop=5000, nt=None,\n",
    "        max_ram_mb=100000, kappa=0.01, seed=None, observables='all',\n",
    "        keep_pulses='prev', single_excitation_subspace=False,\n",
    "        config='config'):\n",
    "    \"\"\"OCT model with identical pulses on all nodes\"\"\"\n",
    "    n_nodes = slh.n_nodes\n",
    "    # fix the controls to have one pulse for the initial node, on pulse for\n",
    "    # the final node, and the same pulse for the intermediate nodes\n",
    "    controls = dicke_guess_controls(\n",
    "        slh=slh, theta=theta, T=T, E0_cycles=E0_cycles, nt=nt, kappa=kappa)\n",
    "    control_1_sym = Symbol('Omega_1')\n",
    "    control_1_pulse = controls[control_1_sym]\n",
    "    control_N_sym = Symbol('Omega_%d' % n_nodes)\n",
    "    control_N_pulse = controls[control_N_sym]\n",
    "    control_i_sym = Symbol('Omega')\n",
    "    control_i_pulse = controls[Symbol('Omega_2')]\n",
    "    controls = {\n",
    "        control_1_sym: control_1_pulse,\n",
    "        control_i_sym: control_i_pulse,\n",
    "        control_N_sym: control_N_pulse,}\n",
    "    control_mapping = {}\n",
    "    ctrl_syms = [Symbol('Omega_%d' % ind) for ind in range(1, n_nodes+1)]\n",
    "    for i, ctrl_sym in enumerate(ctrl_syms):\n",
    "        if i == 0:\n",
    "            control_mapping[ctrl_sym] = control_1_sym\n",
    "        elif i == len(ctrl_syms)-1:  # last\n",
    "            control_mapping[ctrl_sym] = control_N_sym\n",
    "        else:\n",
    "            control_mapping[ctrl_sym] = control_i_sym\n",
    "    slh = slh.substitute(control_mapping)\n",
    "    # end\n",
    "    assert single_excitation_subspace\n",
    "    qdyn_model = make_single_excitation_qdyn_oct_model(\n",
    "        slh, num_vals=num_vals(theta=theta, n_nodes=n_nodes, kappa=kappa),\n",
    "        controls=controls, energy_unit='dimensionless',\n",
    "        mcwf=mcwf, non_herm=non_herm, oct_target='dicke_1',\n",
    "        lambda_a=lambda_a, iter_stop=iter_stop, keep_pulses=keep_pulses,\n",
    "        J_T_conv=J_T_conv, max_ram_mb=max_ram_mb, seed=seed,\n",
    "        observables=observables)\n",
    "    qdyn_model.user_data['state_label'] = '10'  # for prop\n",
    "    if (mcwf, non_herm) == (False, False):\n",
    "        qdyn_model.user_data['rho'] = True\n",
    "    qdyn_model.write_to_runfolder(rf, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.538451Z",
     "start_time": "2018-06-16T19:24:43.443850Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_create_runfolder():\n",
    "    \"\"\"Create all necessary runfolders for the runs defined in params_df\"\"\"\n",
    "    jobs = {}\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        n_nodes = row['nodes']\n",
    "        nt = row['nt']\n",
    "        try:\n",
    "            slh = SLH_MODELS[n_nodes]\n",
    "        except KeyError:\n",
    "            slh = network_slh(\n",
    "                n_cavity=2, n_nodes=n_nodes, topology='open')\n",
    "            SLH_MODELS[n_nodes] = slh\n",
    "        if rf in jobs:\n",
    "            continue\n",
    "        mcwf = {  #   variant => whether to use MCWF\n",
    "            'rho': False, 'nonherm': False, 'independent': True,\n",
    "            'cross': True}\n",
    "        jobs[rf] = {\n",
    "            'name': str(rf),\n",
    "            'actions': [\n",
    "                # write the density matrix propagation data\n",
    "                (write_dicke_single_model_three_pulses, [slh, ], dict(\n",
    "                    rf=rf, T=row['T'], theta=0, nt=nt,\n",
    "                    kappa=1.0, E0_cycles=2,\n",
    "                    mcwf=False, non_herm=False, # this defines rho-prop\n",
    "                    single_excitation_subspace=True,\n",
    "                    config='config_rho')),\n",
    "                # write the data for the optimization\n",
    "                (write_dicke_single_model_three_pulses, [slh, ], dict(\n",
    "                    rf=rf, T=row['T'], theta=0, nt=nt,\n",
    "                    kappa=1.0, E0_cycles=2, mcwf=mcwf[row['variant']],\n",
    "                    non_herm=(row['variant'] != 'rho'),\n",
    "                    lambda_a=row['lambda_a'], keep_pulses='all',\n",
    "                    iter_stop=int(row['iter_stop']), J_T_conv=row['J_T_conv'],\n",
    "                    single_excitation_subspace=True,\n",
    "                    config='config'))],\n",
    "            'targets': [join(rf, 'config_rho'), join(rf, 'config')],\n",
    "            'uptodate': [True, ] # up to date if targets exist\n",
    "        }\n",
    "    for job in jobs.values():\n",
    "        yield job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.590963Z",
     "start_time": "2018-06-16T19:24:43.540950Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_update_runfolder():\n",
    "    \"\"\"For every row in params_df, update the config file in the appropriate\n",
    "    runfolder with the value in that row\n",
    "    (adjusting lambda_a, iter_stop and J_T_conv only)\"\"\"\n",
    "    rf_jobs = defaultdict(list)\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        # we only update the config after any earlier optimization has finished\n",
    "        task_dep = ['wait_for_optimization:%s' % ind2 for ind2 in rf_jobs[rf]]\n",
    "        rf_jobs[rf].append(ind)\n",
    "        yield {\n",
    "            'name': str(ind),\n",
    "            'actions': [\n",
    "                (update_config, [], dict(\n",
    "                    rf=rf, lambda_a=row['lambda_a'],\n",
    "                    iter_stop=int(row['iter_stop']),\n",
    "                    J_T_conv=row['J_T_conv']))],\n",
    "            'file_dep': [join(rf, 'config')],\n",
    "            'uptodate': [False, ],  # always run task\n",
    "            'task_dep': task_dep}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.644634Z",
     "start_time": "2018-06-16T19:24:43.593361Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_submit_optimization():\n",
    "    \"\"\"Run optimization for every runfolder from params_df\"\"\"\n",
    "    rf_jobs = defaultdict(list)\n",
    "    optimization_variant = {\n",
    "        'rho': 'normal',\n",
    "        'nonherm': 'normal',\n",
    "        'independent': 'normal',\n",
    "        'cross': 'cross',\n",
    "    }\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        task_dep = ['wait_for_optimization:%s' % ind2 for ind2 in rf_jobs[rf]]\n",
    "        task_dep.append('update_runfolder:%s' % ind)\n",
    "        yield {\n",
    "            'name': str(ind),\n",
    "            'actions': [\n",
    "                (submit_optimization, [rf, ],\n",
    "                 dict(n_trajs=row['n_trajs'],\n",
    "                      variant=optimization_variant[row['variant']]))],\n",
    "                # 'task' keyword arg is added automatically\n",
    "            'task_dep': task_dep,\n",
    "            'uptodate': [(pulses_uptodate, [], {'rf': rf}), ],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.685579Z",
     "start_time": "2018-06-16T19:24:43.647244Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_wait_for_optimization():\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        yield {\n",
    "            'name': str(ind),\n",
    "            'task_dep': ['submit_optimization:%d' % ind],\n",
    "            'actions': [\n",
    "                (wait_for_clusterjob, [join(rf, 'oct.job.dump')], {}),]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional tasks for evaluating the optimization success through a propagation\n",
    "in Liouville space are defined farther below\n",
    "\n",
    "##  OCT Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.745444Z",
     "start_time": "2018-06-16T19:24:43.688005Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_data_str = r'''\n",
    "# nodes   T    nt  lambda_a      variant  n_trajs   iter_stop   J_T_conv\n",
    "     20  50   500     0.001  independent        1        5000       1e-8\n",
    "'''\n",
    "params_df = pd.read_fwf(\n",
    "        StringIO(params_data_str), comment='#', header=1,\n",
    "        names=[\n",
    "            'nodes', 'T', 'nt', 'lambda_a', 'variant', 'n_trajs', 'iter_stop',\n",
    "            'J_T_conv'],\n",
    "        converters={\n",
    "            'nodes': int, 'T': float, 'nt': int, 'lambda_a': float,\n",
    "            'variant': str, 'n_trajs': int, 'iter_stop': int,\n",
    "            'J_T_conv': float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.797393Z",
     "start_time": "2018-06-16T19:24:43.748168Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodes     T   nt  lambda_a      variant  n_trajs  iter_stop      J_T_conv\n",
      "0     20  50.0  500     0.001  independent        1       5000  1.000000e-08\n"
     ]
    }
   ],
   "source": [
    "print(params_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T19:24:43.840002Z",
     "start_time": "2018-06-16T19:24:43.800032Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "root = logging.getLogger()\n",
    "for handler in root.handlers[:]:\n",
    "    root.removeHandler(handler)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, filename='./data/oct_single_excitation_three_pulses.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.334Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  create_runfolder:./data/oct_single_excitation_three_pulses/20nodesT50_independent_ntrajs1\n"
     ]
    }
   ],
   "source": [
    "%doit -n 40 create_runfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- create_runfolder:./data/oct_single_excitation_three_pulses/20nodesT50_independent_ntrajs1\n",
      ".  update_runfolder:0\n",
      ".  submit_optimization:0\n",
      ".  wait_for_optimization:0\n"
     ]
    }
   ],
   "source": [
    "%doit -n 40 wait_for_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(SLH_PICKLE_FILE, 'wb') as pickle_fh:\n",
    "    pickle.dump(SLH_MODELS, pickle_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T19:40:32.953382Z",
     "start_time": "2018-04-30T19:40:32.878051Z"
    }
   },
   "source": [
    "## Evaluate error exactly from density matrix propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.341Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RHO_PROP_ITERS = np.arange(6000, step=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_rho_prop_create_custom_config():\n",
    "    \"\"\"For every optimized pulse, at intermediate iteration numbers,\n",
    "    write a custom config file the will propagate this pulse\"\"\"\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        for oct_pulse_file in glob(join(rf, 'pulse1.oct.dat.0*')):\n",
    "            oct_iter = int(os.path.splitext(oct_pulse_file)[-1][1:])\n",
    "            if oct_iter not in RHO_PROP_ITERS:\n",
    "                continue  # skip; we don't want to propagate *all* pulses\n",
    "            assert os.path.isfile(oct_pulse_file.replace('pulse1', 'pulse2'))\n",
    "            config_out = 'config_rho.%08d' % oct_iter\n",
    "            yield {\n",
    "                'name': str(rf) + \"/%s\" % config_out,\n",
    "                'actions': [\n",
    "                    (write_rho_prop_custom_config,\n",
    "                     [rf, oct_iter, config_out])],\n",
    "                'targets': [join(rf, config_out)],\n",
    "                'uptodate': [True, ] # up to date if target exists\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.345Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_evaluate_rho_prop_error():\n",
    "    \"\"\"For every custom rho prop config file, perform the propagation\"\"\"\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        for custom_config in glob(join(rf, 'config_rho.0*')):\n",
    "            oct_iter = int(os.path.splitext(custom_config)[-1][1:])\n",
    "            yield {\n",
    "                'name': str(rf) + \"/%s\" % custom_config,\n",
    "                'actions': [\n",
    "                    (run_traj_prop, [rf, ], dict(\n",
    "                        n_trajs=1, n_procs=None, use_oct_pulses=False,\n",
    "                        config=os.path.split(custom_config)[-1]))],\n",
    "                'targets': [join(rf, 'P_target.dat.%08d' % oct_iter)],\n",
    "                'file_dep': [custom_config],\n",
    "                'uptodate': [True, ] # up to date if target exists\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.347Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_collect_rho_prop_errors():\n",
    "    \"\"\"For every custom rho prop config file, perform the propagation\"\"\"\n",
    "    for ind, row in params_df.iterrows():\n",
    "        rf = runfolder(row)\n",
    "        P_target_obs_files = glob(join(rf, 'P_target.dat.0*'))\n",
    "        target_file = join(rf, 'rho_prop_error.dat')\n",
    "        yield {\n",
    "            'name': target_file,\n",
    "            'actions': [\n",
    "                (collect_rho_prop_errors, P_target_obs_files,\n",
    "                 dict(outfile=target_file))],\n",
    "            'targets': [target_file],\n",
    "            'file_dep': P_target_obs_files,\n",
    "            'uptodate': [False, ]\n",
    "            # We always create a new file\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.350Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%doit -n 78 rho_prop_create_custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.352Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%doit -n 78 evaluate_rho_prop_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T19:24:38.354Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%doit -n 78 collect_rho_prop_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1006px",
    "left": "0px",
    "right": "748px",
    "top": "97px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
